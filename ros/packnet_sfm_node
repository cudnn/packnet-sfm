#!/usr/bin/env python3
import rospy
from sensor_msgs.msg import Image

import numpy as np
import os
import torch
import time

import cv2
from cv_bridge import CvBridge, CvBridgeError

import packnet_sfm

from packnet_sfm.models.model_wrapper import ModelWrapper
from packnet_sfm.datasets.augmentations import resize_image, to_tensor
from packnet_sfm.utils.horovod import hvd_init, rank, world_size, print0
from packnet_sfm.utils.image import load_image, interpolate_image
from packnet_sfm.utils.config import parse_test_file
from packnet_sfm.utils.load import set_debug
from packnet_sfm.utils.depth import write_depth, inv2depth, viz_inv_depth
from packnet_sfm.utils.logging import pcolor

from packnet_sfm.utils.types import is_seq, is_tensor

class DepthInference:
    def __init__(self):
        self.bridge = CvBridge()

        self.model_wrapper = None
        self.network_input_shape = None
        self.original_input_shape = None
        self.rgb_img_msg = None
        self.depth_img_msg = None
        self.set_model_wrapper()

        # Communication
        self.pub_rgb_image = rospy.Publisher('/camera/color/image_raw', Image, queue_size=100)
        self.pub_depth_image = rospy.Publisher('/camera/depth/image_raw', Image, queue_size=100)

        # queue_size=None to process only the last message
        rospy.Subscriber("/video/image_raw", Image, self.cb_image, queue_size=1)

        rate = rospy.Rate(10) # 10hz
        while not rospy.is_shutdown():
            if self.rgb_img_msg is None:
                continue

            self.process(self.rgb_img_msg)
            rate.sleep()


    def set_model_wrapper(self):

        config, state_dict = parse_test_file("/home/jedsadakorn/packnet_ws/src/packnet_sfm/models/PackNet01_MR_velsup_CStoK.ckpt")
        
        self.set_network_input_shape(config)

        # Initialize model wrapper from checkpoint arguments
        self.model_wrapper = ModelWrapper(config, load_datasets=False)
        # Restore monodepth_model state
        self.model_wrapper.load_state_dict(state_dict)

        if torch.cuda.is_available():
            self.model_wrapper = self.model_wrapper.to('cuda:{}'.format(rank()), dtype=None)
        
        # Set to eval mode
        self.model_wrapper.eval()
    

    def set_network_input_shape(self, config):
        self.network_input_shape = config.datasets.augmentation.image_shape


    def process(self, rgb_img_msg):

        try:
            rgb_image = self.bridge.imgmsg_to_cv2(rgb_img_msg, "bgr8")
        except CvBridgeError as e:
            print(e)
            
        # shrink the image to fit NN input
        rgb_image = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2RGB)
        # rgb_image = cv2.resize(rgb_image, (self.network_input_shape[1], self.network_input_shape[0]), interpolation=cv2.INTER_LANCZOS4)
        rgb_image = cv2.resize(rgb_image, (self.network_input_shape[1], self.network_input_shape[0]))
        rgb_image = to_tensor(rgb_image).unsqueeze(0)

        if torch.cuda.is_available():
            rgb_image = rgb_image.to('cuda:{}'.format(rank()), dtype=None)
        
        # Depth inference (returns predicted inverse depth)
        pred_inv_depth = self.model_wrapper.depth(rgb_image)

        # resize from PIL image and cv2 has different convention about the image shape 

        pred_inv_depth_resized = interpolate_image(pred_inv_depth, (self.original_input_shape[0], self.original_input_shape[1]), mode='bicubic')
        
        # convert inverse depth to depth image
        depth_img = self.write_depth(self.inv2depth(pred_inv_depth_resized))
        print(rgb_img_msg.header.seq)
        filename = "/home/jedsadakorn/packnet_ws/src/packnet_sfm/inferences/test/{:06d}.png".format(rgb_img_msg.header.seq)
        cv2.imwrite(filename, depth_img)

        depth_img_msg = self.bridge.cv2_to_imgmsg(depth_img, encoding="mono16")

        rgb_img_msg.header.stamp = rospy.Time.now()
        depth_img_msg.header.stamp = rospy.Time.now()
        rgb_img_msg.header.frame_id = "left_image"
        depth_img_msg.header.frame_id = "left_image"

        self.pub_rgb_image.publish(rgb_img_msg)
        self.pub_depth_image.publish(depth_img_msg)


    def inv2depth(self, inv_depth):
        """
        Invert an inverse depth map to produce a depth map

        Parameters
        ----------
        inv_depth : torch.Tensor or list of torch.Tensor [B,1,H,W]
            Inverse depth map

        Returns
        -------
        depth : torch.Tensor or list of torch.Tensor [B,1,H,W]
            Depth map
        """
        if is_seq(inv_depth):
            return [inv2depth(item) for item in inv_depth]
        else:
            return 1. / inv_depth


    def write_depth(self, depth):
        """
        Write a depth map to file, and optionally its corresponding intrinsics.

        This code is modified to export compatible-format depth image to openVSLAM

        Parameters
        ----------
        depth : np.array [H,W]
            Depth map
        """
        # If depth is a tensor
        if is_tensor(depth):
            depth = depth.detach().squeeze().cpu()
            depth = np.clip(depth, 0, 100)
            depth = np.uint16(depth * 256)

        return depth

    def cb_image(self, data):
        rospy.loginfo(data.header.seq)
        self.rgb_img_msg = data
        self.original_input_shape = (data.height, data.width)


if __name__ == "__main__":
    rospy.init_node('packnet_sfm_node')
    depth_inference_node = DepthInference()
